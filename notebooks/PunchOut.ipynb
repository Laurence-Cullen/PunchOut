{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.layers import GaussianNoise\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "import keras \n",
    "from keras.models import Model\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications import MobileNetV2\n",
    "import time\n",
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    images = np.array(data['filenames'])\n",
    "    images_targets = np_utils.to_categorical(np.array(data['target']), 5) # [1,0] is no_punch, [0,1] is right_punch\n",
    "    return images, images_targets\n",
    "\n",
    "#load training dataset\n",
    "train_images, train_targets = load_dataset('../Images/train') \n",
    "test_images, test_targets = load_dataset('../Images/test')\n",
    "\n",
    "print('There are %s total training images.\\n' % len(train_images))\n",
    "print('There are %s total testing images.\\n' % len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions to load the images into 4D numpy tensors, load data into tensors and create a training-validation split\n",
    "# out of the training data.\n",
    "\n",
    "# Functions to load images into 4d Numpy arrays.\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process and load the data for Keras\n",
    "train_tensors = paths_to_tensor(train_images).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_images).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.imshow(train_tensors[416, :,:,:])\n",
    "plt.show()\n",
    "\n",
    "train_targets[416]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some of the training tensors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range (400,425):\n",
    "    plt.imshow(train_tensors[i, :,:,:])\n",
    "    plt.show()\n",
    "    print(train_targets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the training data into training and validation sets.\n",
    "train_tensors, valid_tensors, train_targets, valid_targets = train_test_split(train_tensors, train_targets, \n",
    "                                                                             test_size=0.2, \n",
    "                                                                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some adjustable variables outside the function and setup CNN compiling, fiting and testing function with early-stopping\n",
    "# and model-checkpointing. Reload best weights and test model with best weights on testing set.\n",
    "\n",
    "epochs = 1000\n",
    "patience = 20\n",
    "rmsprop_lowLR = optimizers.RMSprop(lr=0.00001)\n",
    "optimizer= rmsprop_lowLR\n",
    "\n",
    "def model_compile_fit(model):\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(\"Optimizer:\", optimizer)\n",
    "    print(\"Patience:\", patience)\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=patience, verbose=0, mode='auto', \n",
    "          baseline=None, restore_best_weights=False)\n",
    "    \n",
    "    model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer,\n",
    "          early_stopping], verbose=2)\n",
    "    \n",
    "    model.load_weights('saved_models/weights.best.from_scratch.hdf5')\n",
    "    \n",
    "    # get index of predicted action for each image in test set\n",
    "    action_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "    # report test accuracy\n",
    "    test_accuracy = 100*np.sum(np.array(action_predictions)==np.argmax(test_targets, axis=1))/len(2) #len(2) is len(diff actions)\n",
    "    print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same function as above but with ImageDataGenerator to allow image augmentation.\n",
    "\n",
    "def augmented_data_model_compile_fit(model):\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(\"Optimizer:\", optimizer)\n",
    "    print(\"Patience:\", patience)\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=patience, verbose=0, mode='auto', \n",
    "          baseline=None, restore_best_weights=False)\n",
    "    \n",
    "    #Create and configure augmented image generator\n",
    "\n",
    "    datagen =ImageDataGenerator(width_shift_range=0.1, # randomly shift images horizontally (10% of total width)\n",
    "                                height_shift_range=0.1, # randomly shift images vertically (10% of total height)\n",
    "                                zoom_range=0.2) # range for random zoom)\n",
    "              \n",
    "    \n",
    "    #fit augmented image generator on data\n",
    "    datagen.fit(train_tensors)\n",
    "    \n",
    "    batch_size = 20\n",
    "    \n",
    "    # train the model\n",
    "    model.fit_generator(datagen.flow(train_tensors, train_targets, batch_size=batch_size),\n",
    "                          steps_per_epoch=3*(train_tensors.shape[0]//batch_size),\n",
    "                          epochs=epochs, verbose=2, callbacks=[checkpointer, early_stopping],\n",
    "                         validation_data=(valid_tensors, valid_targets))\n",
    "    \n",
    "    # load the weights that generated the best validation accuracy\n",
    "    model.load_weights('saved_models/weights.best.from_scratch.hdf5')\n",
    "       \n",
    "    # get index of predicted action for each image in test set\n",
    "    action_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "    # report test accuracy\n",
    "    test_accuracy = 100*np.sum(np.array(action_predictions)==np.argmax(test_targets, axis=1))/len(action_predictions) \n",
    "    print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience= 15\n",
    "\n",
    "aug_model9 = Sequential()\n",
    "aug_model9.add(Conv2D(input_shape=(224,224,3), filters=16, kernel_size=(5,5), padding='same', activation='relu', strides=1))\n",
    "aug_model9.add(MaxPooling2D(pool_size=(3,3)))\n",
    "aug_model9.add(BatchNormalization())\n",
    "aug_model9.add(Conv2D(input_shape=train_tensors.shape, filters=32, kernel_size=(4,4), padding='same', activation='relu', strides=1))\n",
    "aug_model9.add(MaxPooling2D(pool_size=(2,2)))\n",
    "aug_model9.add(BatchNormalization())\n",
    "aug_model9.add(Conv2D(input_shape=train_tensors.shape, filters=64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "aug_model9.add(MaxPooling2D(pool_size=(2,2), strides=1))\n",
    "aug_model9.add(BatchNormalization())\n",
    "aug_model9.add(Conv2D(input_shape=(224,224,3), filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "aug_model9.add(MaxPooling2D(pool_size=(2,2), strides=1))\n",
    "aug_model9.add(BatchNormalization())\n",
    "aug_model9.add(Conv2D(input_shape=(224,224,3), filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "aug_model9.add(MaxPooling2D(pool_size=(2,2), strides=1))\n",
    "aug_model9.add(BatchNormalization())\n",
    "aug_model9.add(Conv2D(input_shape=(224,224,3), filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "aug_model9.add(MaxPooling2D(pool_size=(2,2), strides=1))\n",
    "aug_model9.add(BatchNormalization())\n",
    "aug_model9.add(Conv2D(input_shape=(224,224,3), filters=1024, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "aug_model9.add(MaxPooling2D(pool_size=(2,2), strides=1))\n",
    "aug_model9.add(BatchNormalization())\n",
    "aug_model9.add(GlobalAveragePooling2D(data_format=None))\n",
    "aug_model9.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "aug_model9.summary()\n",
    "augmented_data_model_compile_fit(aug_model9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights that generated the best validation accuracy\n",
    "aug_model9.load_weights('saved_models/weights.best.from_scratch.hdf5')\n",
    "       \n",
    "# get index of predicted action for each image in test set\n",
    "action_predictions = [np.argmax(aug_model9.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(action_predictions)==np.argmax(test_targets, axis=1))/len(action_predictions) \n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights that generated the best validation accuracy\n",
    "transfer_model.load_weights('saved_models/weights.best.transfer.hdf5')\n",
    "       \n",
    "# get index of predicted action for each image in test set\n",
    "action_predictions = [np.argmax(transfer_model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_bottlenecks]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(action_predictions)==np.argmax(test_targets, axis=1))/len(action_predictions) \n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Fine tuning MobileNetV1\n",
    "patience = 15\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "mobilenetV1_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "mobilenetV1_model.summary()\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(fine_tuned_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in mobilenetV1_model.layers[:20]:\n",
    "    layer.trainable = False\n",
    "for layer in mobilenetV1_model.layers[20:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "mobilenetV1_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0003), metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=patience, verbose=0, mode='auto', \n",
    "          baseline=None, restore_best_weights=False)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.MobileNetV1.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "mobilenetV1_model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer, early_stopping], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights that generated the best validation accuracy\n",
    "mobilenetV1_model.load_weights('saved_models/weights.best.MobileNetV1.hdf5')\n",
    "       \n",
    "# get index of predicted action for each image in test set\n",
    "action_predictions = [np.argmax(mobilenetV1_model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(action_predictions)==np.argmax(test_targets, axis=1))/len(action_predictions) \n",
    "print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "\n",
    "#Compute average prediction time\n",
    "computational_times = []\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    start = time.time()\n",
    "    mobilenetV1_model.predict(np.expand_dims(test_tensors[i], axis=0))\n",
    "    end = time.time()\n",
    "    \n",
    "    elapsed = end - start\n",
    "    computational_times.append(elapsed)\n",
    "\n",
    "print(\"Average computational time per prediction:\", np.sum(computational_times)/len(computational_times)*1000, \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Fine tuning MobileNetV2\n",
    "patience = 10\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False)\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "mobilenetV2_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "mobilenetV2_model.summary()\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(fine_tuned_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in mobilenetV2_model.layers[:70]:\n",
    "    layer.trainable = False\n",
    "for layer in mobilenetV2_model.layers[70:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "mobilenetV2_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0003), metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=patience, verbose=0, mode='auto', \n",
    "          baseline=None, restore_best_weights=False)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.MobileNetV2.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "mobilenetV2_model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer, early_stopping], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights that generated the best validation accuracy\n",
    "mobilenetV2_model.load_weights('saved_models/weights.best.MobileNetV2.hdf5')\n",
    "       \n",
    "# get index of predicted action for each image in test set\n",
    "action_predictions = [np.argmax(mobilenetV2_model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(action_predictions)==np.argmax(test_targets, axis=1))/len(action_predictions) \n",
    "print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "\n",
    "#Compute average prediction time\n",
    "computational_times = []\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    start = time.time()\n",
    "    mobilenetV2_model.predict(np.expand_dims(test_tensors[i], axis=0))\n",
    "    end = time.time()\n",
    "    \n",
    "    elapsed = end - start\n",
    "    computational_times.append(elapsed)\n",
    "\n",
    "print(\"Average computational time per prediction: {.3f} ms\".format(np.sum(computational_times)/len(computational_times)*1000) m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
